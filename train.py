import os
import sys 
import torch
import glob
import pandas as pd
import numpy as np
import argparse



PROJECT_DIR = os.environ.get('PROJECT_DIR') 
sys.path.append(os.path.join(PROJECT_DIR))
sys.path.append(os.path.join(PROJECT_DIR, "utils"))
sys.path.append(os.path.join(PROJECT_DIR, "src")) 
sys.path.append(os.path.join(PROJECT_DIR, "datase_utils")) 


from src.camil import CAMIL  # Assuming CAMIL is the model class from camil.py
from data.camelyon16_dataset import CustomDataset

from utils.utils import train




def parse_arguments():
    """
    Parses the command line arguments.
    """
    parser = argparse.ArgumentParser(description="Training configuration for CAMIL model")
    parser.add_argument('--dry_run', type=bool, default=False, help="test running okay? ")    
    # Dataset and paths
    parser.add_argument('--train_or_test', type=str, choices=["train", "test"], default='train', help="training or inferencing")  
    parser.add_argument('--dataset_name', type=str, choices=["camelyon16"], default='camelyon16', help="dataset name") 
    parser.add_argument('--input_shape', type=int, default=512, help="Input feature dimension (default: 512)")
    parser.add_argument('--n_classes', type=int, default=2, help="Number of output classes (default: 2)")
    parser.add_argument('--subtyping', type=bool, default=False, help="Whether to use subtyping (default: False)")
    # Training parameters
    parser.add_argument('--epochs', type=int, default=30, help="Number of epochs to train (default: 10)")
    parser.add_argument('--learning_rate', type=float, default=1e-3, help="Learning rate (default: 1e-3)")
    
    # Device (GPU/CPU)
    parser.add_argument('--device', type=str, choices=["cpu", "cuda"], default="cuda", help="Device for training (default: cuda)")

    return parser.parse_args()

def main():
    # Parse arguments
    args = parse_arguments()
    
    #TODO: later args should be save in a YML file ! 
    print(f"Training for dataset {format(args.dataset_name)}")
    train_or_test_or_val = 'train'
    # args.epochs = NUM_EPOCH 
    if args.dataset_name == 'camelyon16':     
        args.label_file = os.path.join(PROJECT_DIR, "data/label_files/camelyon_data.csv")
        args.split_filepath = os.path.join(PROJECT_DIR, "data/camelyon_csv_splits/splits_0.csv")
        args.feature_folder =os.path.join(PROJECT_DIR,'data/camelyon16_features/h5_files') 
        args.save_dir = os.path.join(PROJECT_DIR, "data/weights") 
        args.log_dir = os.path.join(PROJECT_DIR, "data/logs")  
    # Initialize the model
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
 
    model = CAMIL(args)
    model.to(device)   

    import datetime
    # Generate the dynamic save path with dataset name, timestamp, and "completed"
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M")
    save_path = f"{args.save_dir}/{args.dataset_name}_{timestamp}_completed.pth" 
    log_path = f"{args.log_dir}/{args.dataset_name}_{timestamp}.json"  

    if args.dry_run == True: 
        args.epochs = 30 
        print("RUNING THE DRY RUN---->>> ")
        train_dataset = CustomDataset(
            train_or_test_or_val = 'train',
            split_filepath=args.split_filepath, 
            label_file=args.label_file,
            feature_folder=args.feature_folder, 
            feature_file_end ='h5',  
            shuffle=True,  
            dry_run=True

        )
            # Create dataset
        val_dataset = CustomDataset(
            train_or_test_or_val = 'val',
            split_filepath=args.split_filepath, 
            label_file=args.label_file,
            feature_folder=args.feature_folder, 
            feature_file_end ='h5',  
            shuffle=True, 
            dry_run=True
        )
    else: 
        print(f"Running the training with {args.epochs} epochs")
        # Create dataset
        train_dataset = CustomDataset(
            train_or_test_or_val = 'train',
            split_filepath=args.split_filepath, 
            label_file=args.label_file,
            feature_folder=args.feature_folder, 
            feature_file_end ='h5',  
            shuffle=True,  
        )
            # Create dataset
        val_dataset = CustomDataset(
            train_or_test_or_val = 'val',
            split_filepath=args.split_filepath, 
            label_file=args.label_file,
            feature_folder=args.feature_folder, 
            feature_file_end ='h5',  
            shuffle=True
        )

    
    # Print the length of the train and validation datasets
    print(f"Length of train_dataset: {len(train_dataset)}")
    print(f"Length of val_dataset: {len(val_dataset)}")
    # # Set device (GPU or CPU)
    # device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device = torch.device("cpu")
    # # Call the train function
    train(
        model, 
        train_dataset,
        val_dataset, 
        epochs=args.epochs, 
        learning_rate=args.learning_rate, 
        device=device, 
        save_path=save_path, 
        log_file=log_path
        )

    
if __name__ == '__main__':
    main()
